{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabdaaee-c410-47d1-8779-d46772c54157",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparing felsenstein with arDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ceb1a07-5b28-49b1-8f59-1f63fb7053ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "SystemError: ../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m: No such file or directory",
     "output_type": "error",
     "traceback": [
      "SystemError: ../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m: No such file or directory",
      "",
      "Stacktrace:",
      " [1] gzopen(fname::String, gzmode::String, gz_buf_size::Int64)",
      "   @ GZip ~/.julia/packages/GZip/vS3gf/src/gz.jl:193",
      " [2] gzopen(fname::String, gzmode::String, gz_buf_size::Int64)",
      "   @ GZip ~/.julia/packages/GZip/vS3gf/src/gz.jl:206 [inlined]",
      " [3] FastaReader",
      "   @ ~/.julia/packages/FastaIO/nZe63/src/FastaIO.jl:44 [inlined]",
      " [4] FastaIO.FastaReader(f::DCAUtils.ReadFastaAlignment.var\"#1#2\"{Float64}, filename::String, T::Type)",
      "   @ FastaIO ~/.julia/packages/FastaIO/nZe63/src/FastaIO.jl:105",
      " [5] FastaReader",
      "   @ FastaIO ~/.julia/packages/FastaIO/nZe63/src/FastaIO.jl:105 [inlined]",
      " [6] read_fasta_alignment(filename::String, max_gap_fraction::Float64)",
      "   @ DCAUtils.ReadFastaAlignment ~/.julia/packages/DCAUtils/kq0WV/src/read_fasta_alignment.jl:35",
      " [7] top-level scope",
      "   @ In[1]:5"
     ]
    }
   ],
   "source": [
    "using Revise, PhyloTools, TreeTools, DCAUtils, JLD2, PyPlot, Statistics, DelimitedFiles, PottsGauge\n",
    "using AncestralSequenceReconstruction # core package\n",
    "using JLD2 # used to load ArDCA models\n",
    "using TreeTools # to handle p\n",
    "using ArDCA, KitMSA\n",
    "\n",
    "nat_msa  = read_fasta_alignment(\"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\", 0.9);\n",
    "w = compute_weights(nat_msa, 22, 0.2)[1];\n",
    "\n",
    "@load \"../data_Genie/pars_dbd.jld2\"; \n",
    "\n",
    "J_rs = permutedims(J_dbd,[1,3,2,4]);\n",
    "J_zsg, h_zsg = gauge(permutedims(J_dbd, [1,3,2,4]), h_dbd, ZeroSumGauge());\n",
    "PottsGauge.testgauge(J_zsg,h_zsg,J_rs,h_dbd);\n",
    "J = permutedims(J_zsg, [1,3,2,4]); h = deepcopy(h_zsg);\n",
    "\n",
    "#@load \"../data_Genie/pars_dbd.jld2\"; h = h_dbd; J = J_dbd;\n",
    "@load \"../data_Anc/3_start_seq_and_sweeps4DBD_ASR.jld2\"\n",
    "\n",
    "q = 21; L =76;\n",
    "\n",
    "@load \"../data_Genie/3_seqs_sim.jld2\";\n",
    "@load \"../data_Genie/cie_dbd.jld2\";\n",
    "sweeps_sim = res_all[1].steps ./ L;\n",
    "\n",
    "hs = [0 .* h, h, h]; Js = [J, J, 0 .*J] ; names = [\"Only couplings\", \"Standard\", \"Profile\"];\n",
    "alphas = deepcopy(names);\n",
    "mus1 = [1., 10., 50., 100., 200.];\n",
    "#alphas = [0., 0.2, 0.5, 0.7, 1.];\n",
    "\n",
    "\n",
    "eq_samples = [];\n",
    "\n",
    "for i in 1:length(names)\n",
    "    if i == 2\n",
    "        push!(eq_samples, nat_msa)\n",
    "    else\n",
    "        #file_seqs = \"../eq_samples_alpha_for_arDCA/sample_alpha$(alphas[i]).fa\"\n",
    "        file_seqs = \"../eq_sample_for_arDCA/sample_$(alphas[i]).fa\"\n",
    "        push!(eq_samples, read_fasta_alignment(file_seqs,0.9))\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "start_seq = [Int.(eq_samples[i][:,1]) for i in 1:length(alphas)];\n",
    "\n",
    "ens_start = [PhyloTools.energy(start_seq[i], hs[i], Js[i]) for i in 1:length(alphas)];\n",
    "\n",
    "\n",
    "\n",
    "tree_file = \"../data_Anc/DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301.nwk\"\n",
    "leaves_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "hams_leaves =  zeros(length(alphas), length(mus1));\n",
    "hams_intra_leaves = zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1;\n",
    "#generating data and reading it\n",
    "for alpha in names\n",
    "    for n in 1:length(mus1) \n",
    "        @time res1 = run_evolution_ontree(start_seq[num], tree_file, \n",
    "        hs[num], Js[num], mu = mus1[n], p = 0.5);\n",
    "        file_seqs = \"../res_algos/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        leavestofasta(file_seqs, res1) \n",
    "        leaves_msas[num,n] = Int.(read_fasta_alignment(file_seqs,0.9))\n",
    "        hams_leaves[num,n] = mean(ham_dist_nogap(start_seq[num], leaves_msas[num,n]))\n",
    "        hams_intra_leaves[num,n] = pairwise_ham_dist(leaves_msas[num,n], n_seq = 300)\n",
    "    end\n",
    "    num += 1\n",
    "end\n",
    "\n",
    "\n",
    "## doing felsenstein inference\n",
    "res_ASR = zeros(Int, length(alphas), L, length(mus1));\n",
    "pp = Matrix{Matrix{Float64}}(undef, length(alphas), length(mus1));\n",
    "rec_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML =  zeros(length(alphas), length(mus1));\n",
    "hams_ML =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "\n",
    "  \n",
    "#inference with felsenstein\n",
    "\n",
    "num = 1; for alpha in names \n",
    "    for n in 1:length(mus1)\n",
    "        file_seqs = \"../res_algos/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        mu = infer_mu(tree_file, file_seqs)\n",
    "        res, p = Felsenstein2(file_seqs, tree_file, file_seqs, mu)\n",
    "        res_ASR[num,:,n] .= Int.(res)\n",
    "        pp[num,n] = p\n",
    "        rec_msas[num,n] = sampling_ANC(pp[num,n], n_seq = 500)\n",
    "        hams[num,n] = ham_dist_nogap(start_seq[num], rec_msas[num,n])\n",
    "        ens[num,n] = PhyloTools.energy(rec_msas[num,n],  hs[num],  Js[num]) .- ens_start[num]\n",
    "        hams_ML[num,n] = ham_dist_nogap(start_seq[num], res_ASR[num,:,n])\n",
    "        ens_ML[num,n] = PhyloTools.energy(res_ASR[num,:,n], hs[num],  Js[num]) - ens_start[num]\n",
    "    end\n",
    "    num +=1\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "#learning arDCA models on equilibrium data\n",
    "\n",
    "ar_models = []\n",
    "for i in 1:length(names)\n",
    "    if i == 2\n",
    "        file_equil_seqs = \"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\"\n",
    "        arnet,arvar=ardca(file_equil_seqs);\n",
    "        push!(ar_models, AutoRegressiveModel(arnet))\n",
    "    else\n",
    "        file_equil_seqs = \"../eq_sample_for_arDCA/sample_$(names[i]).fa\"\n",
    "        arnet,arvar=ardca(file_equil_seqs);\n",
    "        push!(ar_models, AutoRegressiveModel(arnet))\n",
    "    end\n",
    "end\n",
    "\n",
    "#inference with arDCA\n",
    "\n",
    "res_ASR_arDCA = zeros(Int, length(alphas), L, length(mus1));\n",
    "rec_msas_arDCA = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "hams_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1; for alpha in names\n",
    "@time for n in 1:length(mus1)\n",
    "        fasta_file = \"../res_algos/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    \n",
    "        strategy = ASRMethod(;joint = false, # (default) - joint reconstruction not functional yet\n",
    "            ML = true, # (default)\n",
    "            verbosity = 1, # the default is 0. \n",
    "            optimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "            optimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "            repetitions = 1, # (default) - for Bayesian reconstruction, multiple repetitions of the reconstruction process can be done to sample likely ancestors\n",
    "            );\n",
    "        opt_tree, reconstructed_sequences = infer_ancestral(\n",
    "            tree_file, fasta_file, ar_models[num], strategy\n",
    "            );\n",
    "        res_ASR_arDCA[num,:,n] = KitMSA.string2vec(reconstructed_sequences[\"NODE_1\"]);\n",
    "        node_list=[\"NODE_1\"];\n",
    "        \n",
    "        \n",
    "        #this commented part is for the bayesian arDCA method\n",
    "        strategy_bayesian = ASRMethod(;\n",
    "\tjoint = false, # (default) - joint reconstruction not functional yet\n",
    "\tML = false, # (default)\n",
    "\tverbosity = 1, # the default is 0. \n",
    "\toptimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "\toptimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "\trepetitions = 100,\n",
    "\n",
    ")\n",
    "        \n",
    "    file_out = \"../res_algos/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\";\n",
    "        infer_ancestral(\n",
    "               tree_file, fasta_file, ar_models[num], strategy_bayesian;\n",
    "               alignment_per_node=true, node_list = [\"NODE_1\"], outfasta = file_out);\n",
    "    println(n)\n",
    "    end \n",
    "    num += 1\n",
    "end\n",
    "\n",
    "num = 1\n",
    "for alpha in alphas\n",
    "    for n in 1:length(mus1)\n",
    "        \n",
    "        hams_ML_arDCA[num,n] = ham_dist_nogap(start_seq[num], res_ASR_arDCA[num,:,n])\n",
    "        ens_ML_arDCA[num,n] = PhyloTools.energy(res_ASR_arDCA[num,:,n], hs[num], Js[num]) - ens_start[num] \n",
    "    \n",
    "        rec_msas_arDCA[num,n] = read_fasta_alignment(\"../res_algos/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n], digits = 2))_NODE_1.fa\", 0.9)\n",
    "        \n",
    "        hams_arDCA[num,n] = ham_dist_nogap(start_seq[num], Int.(rec_msas_arDCA[num,n]))\n",
    "        ens_arDCA[num,n] = PhyloTools.energy(rec_msas_arDCA[num,n], hs[num], Js[num]) .- ens_start[num]\n",
    "    end\n",
    "    num += 1\n",
    "end\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(alphas), figsize = (30,5) )\n",
    "num = 1; for alpha in alphas\n",
    "    axs[num].errorbar(hams_leaves[num,:] ./ L, [mean(hams[num,n])./L for n in 1:length(mus1)] ,\n",
    "    yerr = [std(hams[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs[num].scatter(hams_leaves[num,:] ./ L, hams_ML[num,:]./L, marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs[num].errorbar(hams_leaves[num,:] ./ L, [mean(hams_arDCA[num,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs[num].scatter(hams_leaves[num,:] ./ L, hams_ML_arDCA[num,:]./L, marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs[num].set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    num+=1\n",
    "end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"Root-reconstruction \\n hamming\", fontsize = 20)\n",
    "savefig(\"../alpha_ham_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(alphas), figsize = (30,5) )\n",
    "num = 1; for alpha in alphas\n",
    "    axs[num].errorbar(hams_intra_leaves[num,:] ./ L, [mean(hams[num,n])./L for n in 1:length(mus1)] ,\n",
    "    yerr = [std(hams[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs[num].scatter(hams_intra_leaves[num,:] ./ L, hams_ML[num,:]./L, marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs[num].errorbar(hams_intra_leaves[num,:] ./ L, [mean(hams_arDCA[num,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs[num].scatter(hams_intra_leaves[num,:] ./ L, hams_ML_arDCA[num,:]./L, marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs[num].set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    num+=1\n",
    "end\n",
    "fig.supxlabel(\"Leaves pairwise hamming\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"Root-reconstruction \\n hamming\", fontsize = 20)\n",
    "savefig(\"../alpha_intra_ham_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(alphas), figsize = (30,5) )\n",
    "num = 1; for alpha in alphas\n",
    "    axs[num].errorbar(hams_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs[num].scatter(hams_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs[num].errorbar(hams_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs[num].scatter(hams_leaves[num,:] ./ L, ens_ML_arDCA[num,:], marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs[num].set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    num+=1\n",
    "end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../alpha_en_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(alphas), figsize = (30,5) )\n",
    "num = 1; for alpha in alphas\n",
    "    axs[num].errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs[num].scatter(hams_intra_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs[num].errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs[num].scatter(hams_intra_leaves[num,:] ./ L, ens_ML_arDCA[num,:] , marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs[num].set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    num+=1\n",
    "end\n",
    "fig.supxlabel(\"Leaves pairwise hamming\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../alpha_intra_en_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "### plotting as a func of alpha\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(mus1), figsize = (30,5) )\n",
    "for num in 1:length(mus1)\n",
    "    axs[num].errorbar(alphas, [(mean(hams[n,num]) .- mean(hams_arDCA[n,num])) ./L for n in 1:length(alphas)] ,\n",
    "    yerr = [(std(hams[n,num]) .- std(hams_arDCA[n,num]))./L for n in 1:length(alphas)], \n",
    "    color = \"blue\", label = \"Bayes\"); \n",
    "    axs[num].scatter(alphas, (hams_ML[:,num] .- hams_ML_arDCA[:,num]) ./L, marker = \"X\", color = \"blue\", s = 300, label = \"ML\");\n",
    "    axs[num].plot(alphas, [0 for i in 1:length(alphas)], color = \"grey\")\n",
    "end\n",
    "fig.supxlabel(\"Models\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"Root-reconstruction \\n hamming (felse-arDCA)\", fontsize = 20)\n",
    "savefig(\"../1.png\")\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(1, length(mus1), figsize = (30,5) )\n",
    "for num in 1:length(mus1)\n",
    "    axs[num].plot(alphas, [(mean(ens[n,num]) .- mean(ens_arDCA[n,num])) ./L for n in 1:length(alphas)] ,\n",
    "    color = \"blue\", label = \"Bayes\"); \n",
    "    axs[num].scatter(alphas, ens_ML[:,num] .- ens_ML_arDCA[:,num], marker = \"X\", color = \"blue\", s = 300, label = \"ML\");\n",
    "    axs[num].plot(alphas, [0 for i in 1:length(alphas)], color = \"grey\")\n",
    "end\n",
    "fig.supxlabel(\"Models\", fontsize = 20)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"E_ASR - E_wt (felse-arDCA)\", fontsize = 20)\n",
    "savefig(\"../2.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3a938-d5b9-4592-b841-b03642b04743",
   "metadata": {
    "tags": []
   },
   "source": [
    "## single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622114df-2539-477c-be5e-544372c000ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise, PhyloTools, TreeTools, DCAUtils, JLD2, PyPlot, Statistics, DelimitedFiles, PottsGauge\n",
    "using AncestralSequenceReconstruction # core package\n",
    "using JLD2 # used to load ArDCA models\n",
    "using TreeTools # to handle p\n",
    "using ArDCA, KitMSA\n",
    "using Distributions\n",
    "\n",
    "\n",
    "@load \"../data_Genie/pars_dbd.jld2\"; \n",
    "\n",
    "h = h_dbd; J = J_dbd;\n",
    "\n",
    "\n",
    "\n",
    "q = 21; L =76; \n",
    "hs = [h, h, h]; Js = [J, J, 0 .*J] ; names = [\"Standard\", \"Standard\", \"Profile\"];\n",
    "alphas = deepcopy(names); alpha = \"Only_couplings\"; \n",
    "# mus1 = [1., 5., 10., 50., 100.];\n",
    "\n",
    "\n",
    "#tree_file = \"../data_Anc/DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301.nwk\"\n",
    "tree_file = \"../res_trees/DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301_rescaled_depth_16.nwk\"\n",
    "mus1 = 0.33 .* [1., 10., 30.,  50., 100.];\n",
    "\n",
    "\n",
    "#file_seqs = \"../potts_alignment_only_pairwise.fa\"; \n",
    "file_seqs = \"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\"; \n",
    "eq_samples = [read_fasta_alignment(file_seqs,0.9) for _ in 1:3];\n",
    "\n",
    "\n",
    "start_seq = [Int.(eq_samples[i][:,2]) for i in 1:length(alphas)];\n",
    "\n",
    "ens_start = [PhyloTools.energy(start_seq[i], hs[i], Js[i]) for i in 1:length(alphas)];\n",
    "\n",
    "leaves_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "hams_leaves =  zeros(length(alphas), length(mus1));\n",
    "hams_intra_leaves = zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1;  \n",
    "#generating data and reading it\n",
    "#for alpha in names\n",
    "    for n in 1:length(mus1) \n",
    "        @time res1 = run_evolution_ontree(start_seq[num], tree_file, \n",
    "        hs[num], Js[num], mu = mus1[n], temp = 1., p = 0.5);\n",
    "        file_seqs = \"../res_last_tree/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        leavestofasta(file_seqs, res1) \n",
    "        leaves_msas[num,n] = Int.(read_fasta_alignment(file_seqs,0.9))\n",
    "        hams_leaves[num,n] = mean(ham_dist_nogap(start_seq[num], leaves_msas[num,n]))\n",
    "        hams_intra_leaves[num,n] = pairwise_ham_dist(leaves_msas[num,n], n_seq = 300)\n",
    "    end\n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "hams_leaves\n",
    "\n",
    "\n",
    "## doing felsenstein inference\n",
    "res_ASR = zeros(Int, length(alphas), L, length(mus1));\n",
    "pp = Matrix{Matrix{Float64}}(undef, length(alphas), length(mus1));\n",
    "rec_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML =  zeros(length(alphas), length(mus1));\n",
    "hams_ML =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "\n",
    "  \n",
    "#inference with felsenstein\n",
    "\n",
    "num = 1; #for alpha in names \n",
    "    for n in 1:length(mus1)\n",
    "        file_seqs = \"../res_last_tree/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        mu = infer_mu(tree_file, file_seqs)\n",
    "        res, p = Felsenstein2(file_seqs, tree_file, file_seqs, mu)\n",
    "        res_ASR[num,:,n] .= Int.(res)\n",
    "        pp[num,n] = p\n",
    "        rec_msas[num,n] = sampling_ANC(pp[num,n], n_seq = 500)\n",
    "        hams[num,n] = ham_dist_nogap(start_seq[num], rec_msas[num,n])\n",
    "        ens[num,n] = PhyloTools.energy(rec_msas[num,n],  hs[num],  Js[num]) .- ens_start[num]\n",
    "        hams_ML[num,n] = ham_dist_nogap(start_seq[num], res_ASR[num,:,n])\n",
    "        ens_ML[num,n] = PhyloTools.energy(res_ASR[num,:,n], hs[num],  Js[num]) - ens_start[num]\n",
    "    end\n",
    "    #num +=1\n",
    "#end\n",
    "\n",
    "\n",
    "\n",
    "#learning arDCA models on equilibrium data\n",
    "\n",
    "ar_models = []\n",
    "for i in 1:length(names)\n",
    "    #file_equil_seqs = \"../potts_alignment_only_pairwise.fa\"\n",
    "    \n",
    "    file_equil_seqs = \"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\";\n",
    "    arnet,arvar=ardca(file_equil_seqs);\n",
    "    push!(ar_models, AutoRegressiveModel(arnet))\n",
    "end\n",
    "\n",
    "#inference with arDCA\n",
    "\n",
    "res_ASR_arDCA = zeros(Int, length(alphas), L, length(mus1));\n",
    "rec_msas_arDCA = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "hams_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1; #for alpha in names\n",
    "@time for n in 1:length(mus1)\n",
    "        fasta_file = \"../res_last_tree/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    \n",
    "        strategy = ASRMethod(;joint = false, # (default) - joint reconstruction not functional yet\n",
    "            ML = true, # (default)\n",
    "            verbosity = 1, # the default is 0. \n",
    "            optimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "            optimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "            repetitions = 1, # (default) - for Bayesian reconstruction, multiple repetitions of the reconstruction process can be done to sample likely ancestors\n",
    "            );\n",
    "        opt_tree, reconstructed_sequences = infer_ancestral(\n",
    "            tree_file, fasta_file, ar_models[num], strategy\n",
    "            );\n",
    "        res_ASR_arDCA[num,:,n] = KitMSA.string2vec(reconstructed_sequences[\"NODE_1\"]);\n",
    "        node_list=[\"NODE_1\"];\n",
    "        \n",
    "        \n",
    "        #this commented part is for the bayesian arDCA method\n",
    "        strategy_bayesian = ASRMethod(;\n",
    "\tjoint = false, # (default) - joint reconstruction not functional yet\n",
    "\tML = false, # (default)\n",
    "\tverbosity = 1, # the default is 0. \n",
    "\toptimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "\toptimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "\trepetitions = 100,\n",
    "\n",
    ")\n",
    "        \n",
    "    file_out = \"../res_last_tree/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\";\n",
    "        infer_ancestral(\n",
    "               tree_file, fasta_file, ar_models[num], strategy_bayesian;\n",
    "               alignment_per_node=true, node_list = [\"NODE_1\"], outfasta = file_out);\n",
    "    println(n)\n",
    "    end \n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "num = 1\n",
    "#for alpha in alphas\n",
    "    for n in 1:length(mus1)\n",
    "        \n",
    "        hams_ML_arDCA[num,n] = ham_dist_nogap(start_seq[num], res_ASR_arDCA[num,:,n])\n",
    "        ens_ML_arDCA[num,n] = PhyloTools.energy(res_ASR_arDCA[num,:,n], hs[num], Js[num]) - ens_start[num] \n",
    "    \n",
    "        rec_msas_arDCA[num,n] = read_fasta_alignment(\"../res_last_tree/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n], digits = 2))_NODE_1.fa\", 0.9)\n",
    "        \n",
    "        hams_arDCA[num,n] = ham_dist_nogap(start_seq[num], Int.(rec_msas_arDCA[num,n]))\n",
    "        ens_arDCA[num,n] = PhyloTools.energy(rec_msas_arDCA[num,n], hs[num], Js[num]) .- ens_start[num]\n",
    "    end\n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(hams[num,n])./L for n in 1:length(mus1)] ,\n",
    "    yerr = [std(hams[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, hams_ML[num,:]./L, marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(hams_arDCA[num,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, hams_ML_arDCA[num,:]./L, marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"Root-reconstruction \\n hamming\", fontsize = 20)\n",
    "savefig(\"../single_alpha_ham_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(hams[num,n])./L for n in 1:length(mus1)] ,\n",
    "    yerr = [std(hams[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, hams_ML[num,:]./L, marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(hams_arDCA[num,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, hams_ML_arDCA[num,:]./L, marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "fig.supxlabel(\"Leaves pairwise hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"Root-reconstruction \\n hamming\", fontsize = 20)\n",
    "savefig(\"../single_alpha_intra_ham_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, ens_ML_arDCA[num,:], marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../single_alpha_en_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, ens_ML_arDCA[num,:] , marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "fig.supxlabel(\"Leaves pairwise hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../single_alpha_intra_en_ASR_felse_vs_arDCA.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e331e3f-5c2e-4d0d-808b-a1c1822a1f9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Analysing fields and coupling importance and generating eq samples for arDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca16fc-d52e-4d85-9842-aafc22a14f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Genie, DCAUtils, JLD2, PyPlot, Statistics, PottsGauge\n",
    "\n",
    "#@load \"../data_Genie/pars_dbd.jld2\"; h = h_dbd; J = J_dbd;\n",
    "\n",
    "@load \"../data_Genie/pars_dbd.jld2\"; \n",
    "\n",
    "J_rs = permutedims(J_dbd,[1,3,2,4]);\n",
    "J_zsg, h_zsg = gauge(permutedims(J_dbd, [1,3,2,4]), h_dbd, ZeroSumGauge());\n",
    "PottsGauge.testgauge(J_zsg,h_zsg,J_rs,h_dbd);\n",
    "J = permutedims(J_zsg, [1,3,2,4]); h = deepcopy(h_zsg);\n",
    "\n",
    "\n",
    "\n",
    "@load \"../data_Anc/3_start_seq_and_sweeps4DBD_ASR.jld2\"\n",
    "\n",
    "nat_msa  = read_fasta_alignment(\"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\", 0.9);\n",
    "w = compute_weights(nat_msa, 22, 0.2)[1];\n",
    "ens_nat_h = mean(energy(nat_msa, h, 0 .*J))\n",
    "ens_nat_J = mean(energy(nat_msa, 0 * h, J))\n",
    "ens_nat = mean(energy(nat_msa, h, J)) \n",
    "\n",
    "sigm(alpha::Float64) = 1/(1+exp(-alpha))\n",
    "sigm(alpha::Vector{Float64}) = 1 ./ ( 1 .+ exp.( .- alpha))\n",
    "\n",
    "function temp(alphas::Vector{Float64}, x, y)\n",
    "    return 2 .*(x .* alphas .+ y .* (1 .- alphas))./(x+y)\n",
    "end\n",
    "\n",
    "function temp(alpha::Float64, x, y)\n",
    "    return 2 *(x * alpha + y * (1 - alpha))/(x+y)\n",
    "end\n",
    "\n",
    "function field_importance(alphas::Vector{Float64}, x, y)\n",
    "    return ((alphas .* x) .^2) ./ ((alphas .* x).^2 .+ ((1 .- alphas) .* y).^2 )\n",
    "end\n",
    "\n",
    "function field_importance(alpha::Float64, x, y)\n",
    "    return ((alpha * x) ^2) / ((alpha * x) + (1 - alpha) *y)^2\n",
    "end\n",
    "\n",
    "alphas = [0., 0.2, 0.5, 0.7, 1.];\n",
    "#alphas = [0.01*i for i in 1:100];\n",
    "sigm_alphas = sigm(alphas);\n",
    "temps = temp(alphas, ens_nat_h, ens_nat_J)\n",
    "fields_perc = field_importance(alphas, ens_nat_h, ens_nat_J)\n",
    "\n",
    "close(\"all\"); plt.plot(alphas, fields_perc); plt.xlabel(\"Alpha\"); plt.ylabel(\"Energy % due to fields\"); savefig(\"../ciao.png\")\n",
    "close(\"all\"); plt.plot(alphas, temps); savefig(\"../ciao1.png\")     \n",
    "        \n",
    "ens_modified = zeros(length(alphas), size(nat_msa,2));\n",
    "\n",
    "for i in 1:length(alphas)\n",
    "    ens_modified[i,:] = energy(nat_msa, 2*alphas[i]*h, 2 .* (1-alphas[i]) .* J)\n",
    "end\n",
    "\n",
    "close(\"all\"); plt.errorbar(alphas, mean(ens_modified, dims = 2)[:] ./ temps, yerr = std(ens_modified ./temps, dims = 2)[:]\n",
    "    ); plt.xlabel(\"Alpha\"); plt.ylabel(\"Mean nat energy/T\"); savefig(\"../alpha_energy_nat.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q = 21; L =76;\n",
    "\n",
    "start_seq = start_msa[:,1]\n",
    "\n",
    "#start_msa = hcat([start_seq for i in 1:5000]...);\n",
    "#start_msa = nat_msa[:,1:5000];\n",
    "start_msa = Int8.(rand(1:21,L,5000));\n",
    "\n",
    "L = length(start_seq);\n",
    "\n",
    "#alphas = [0., 0.2, 0.5, 0.7, 1.]; MCMC_steps = [10^5, 10^5, 3*10^4, 10^4, 10^4];\n",
    "#MCMC_steps = [10^5, 10^5, 10^5];\n",
    "hs = [0 .* h, h, h]; Js = [J, J, 0 .*J] ; MCMC_steps = [8*10^4, 10^3, 8*10^4\n",
    "    ]; each_steps = [1000, 200,1000]; names = [\"Only couplings\", \"Standard\", \"Profile\"];\n",
    "mean_dist = [[] for i in 1:length(alphas)];\n",
    "mean_intra_dist = [[] for i in 1:length(alphas)];\n",
    "mean_t2_dist = [[] for i in 1:length(alphas)];\n",
    "mean_en = [[] for i in 1:length(alphas)];\n",
    "steps = [[] for i in 1:length(alphas)];\n",
    "steps_t2 = [[] for i in 1:length(alphas)];\n",
    "res_all = [];\n",
    "for i in 1:length(hs)\n",
    "    @time res = run_evolution(start_msa, \n",
    "    hs[i], \n",
    "    Js[i],\n",
    "    p = 0.5, \n",
    "    temp = 1., \n",
    "    N_steps = MCMC_steps[i],  \n",
    "    each_step = 500, \n",
    "    verbose = false);\n",
    "    push!(res_all, res)\n",
    "    for n in 1:length(res_all[i].steps)\n",
    "        push!(mean_dist[i], mean(ham_dist(start_msa, res.step_msa[n])))\n",
    "        push!(mean_intra_dist[i], pairwise_ham_dist(res.step_msa[n], n_seq = 500))\n",
    "        push!(mean_en[i], mean(energy(res.step_msa[n], hs[i], Js[i])))\n",
    "        push!(steps[i], res.steps[n])\n",
    "        if length(findall(x -> x == ((res.steps[n]-1)/2)+1, res.steps)) == 1\n",
    "            push!(steps_t2[i], res.steps[n])\n",
    "            ind = findall(x -> x == ((res.steps[n]-1)/2)+1, res.steps)[1]\n",
    "            #println(ind)\n",
    "            push!(mean_t2_dist[i], mean(Genie.ham_dist(res.step_msa[n], res.step_msa[ind]))) \n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "close(\"all\"); for i in 1:length(hs)\n",
    "    plt.plot(steps[i] ./ L, mean_dist[i] ./ L, label = \"$(names[i])\")\n",
    "end; plt.xscale(\"log\");  plt.xlabel(\"Sweeps\"); plt.ylabel(\"Hamming_from_start\"\n",
    "    ); plt.legend();savefig(\"../ciao_dist.png\")\n",
    "\n",
    "close(\"all\"); for i in 1:length(hs)\n",
    "    plt.plot(steps[i] ./ L, mean_intra_dist[i] ./ L, label = \"$(names[i])\")\n",
    "    plt.scatter(steps_t2[i] ./ L, mean_t2_dist[i] ./ L, label = \"$(names[i])\")\n",
    "end; plt.xscale(\"log\");  plt.xlabel(\"Sweeps\"); plt.ylabel(\"Pairwise Hamming\"\n",
    "    ); plt.legend();savefig(\"../ciao_intra_dist.png\")\n",
    "\n",
    "close(\"all\"); for i in 1:length(hs)\n",
    "    plt.plot(steps[i] ./ L, mean_en[i] , label = \"$(names[i])\")\n",
    "end; plt.xscale(\"log\"); plt.xlabel(\"Sweeps\"); plt.legend();savefig(\"../ciao_en.png\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "using KitMSA\n",
    "for i in 1:length(names)\n",
    "    #file_seqs = \"../eq_samples_alpha_for_arDCA/sample_alpha$(alphas[i]).fa\"\n",
    "    file_seqs = \"../eq_sample_for_arDCA/sample_$(names[i]).fa\"\n",
    "    matrix2fasta(file_seqs, res_all[i].step_msa[end]')\n",
    "end\n",
    "    \n",
    "    \n",
    "#other part\n",
    "\n",
    "using Revise, PhyloTools, DCAUtils, JLD2, PyPlot, Statistics\n",
    "using Distributions, Random\n",
    "\n",
    "L = 20; q = 21; M = 1000;\n",
    "μ = 0.0;      \n",
    "b = sqrt(0.5*0.2);     \n",
    "laplace_dist = Laplace(μ, b);\n",
    "\n",
    "start_msa = rand(1:q, L, M);\n",
    "J_diag = zeros(q,L,q,L);\n",
    "h_diag = zeros(q,L);\n",
    "\n",
    "for i in 1:L\n",
    "    for j in i+1:L\n",
    "        value = rand(laplace_dist)\n",
    "        for a in 1:q\n",
    "            J_diag[a,i,a,j] = 2. #value\n",
    "            J_diag[a,j,a,i] = J_diag[a,i,a,j] \n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "@time new_msa = PhyloTools.reshuffle_entr(start_msa, 0. .* h_diag, 1 .* J_diag, \n",
    "    times = 1.);\n",
    "\n",
    "f1_0, f2_0 = compute_weighted_frequencies(Int8.(start_msa),22, 0.); c_0 = reshape(f2_0 - f1_0*f1_0', q, L, q, L);\n",
    "f1, f2 = compute_weighted_frequencies(Int8.(new_msa),22, 0.); c= reshape(f2 - f1*f1', q, L, q, L);\n",
    "\n",
    "indices = partialsortperm(J_diag[:], 1:1000, rev=true)\n",
    "\n",
    "close(\"all\"); plt.scatter(c_0[indices], c[indices]);plt.plot(\n",
    "    [minimum(c_0[indices]), maximum(c_0[indices])],[minimum(c_0[indices]), maximum(c_0[indices])]\n",
    "    ); savefig(\"../trial.png\")\n",
    "\n",
    "\n",
    "\n",
    "[mean(c_0[:]) mean(c[:])]\n",
    "[std(c_0[:]) std(c[:])]\n",
    "\n",
    "close(\"all\"); plt.hist(c[:],density = true, histtype=\"step\",label = \"reshuf\"); plt.hist(c_0[:],\n",
    "    density = true,histtype = \"step\",label = \"random\"); plt.legend();savefig(\"../hist.png\")\n",
    "\n",
    "#close(\"all\"); plt.plot(steps, ens); plt.xscale(\"log\"); savefig(\"../energia.png\");\n",
    "\n",
    "using Tullio\n",
    "\n",
    "\n",
    "L = 76\n",
    "nat_msa  = read_fasta_alignment(\"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\", 0.9)[1:L,:];\n",
    "rand_msa = rand(1:21,L,10000); \n",
    "f1_0, f2_0 = compute_weighted_frequencies(Int8.(rand_msa),22, 0.); c_0 = reshape(f2_0 - f1_0*f1_0', q, L, q, L);\n",
    "f1, f2 = compute_weighted_frequencies(Int8.(nat_msa),22, 0.); c= reshape(f2 - f1*f1', q, L, q, L);\n",
    "\n",
    "[mean(c_0[:]) mean(c[:])]\n",
    "[std(c_0[:]) std(c[:])]\n",
    "\n",
    "close(\"all\"); plt.hist(c[:],density = true, histtype=\"step\",label = \"reshuf\"); plt.hist(c_0[:],\n",
    "    density = true,histtype = \"step\",label = \"random\"); plt.legend();savefig(\"../hist.png\")\n",
    "\n",
    "close(\"all\")\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns, square aspect\n",
    "\n",
    "# Plot the first matrix\n",
    "cax1 = ax[1].imshow(f2_0 - f1_0*f1_0', cmap=\"viridis\", aspect=\"equal\")\n",
    "fig.colorbar(cax1, ax=ax[1])\n",
    "ax[1].set_title(\"Random\")\n",
    "\n",
    "# Plot the second matrix\n",
    "cax2 = ax[2].imshow(f2 - f1*f1', cmap=\"viridis\", aspect=\"equal\")  # Different colormap for variety\n",
    "fig.colorbar(cax2, ax=ax[2])\n",
    "ax[2].set_title(\"Nat\")\n",
    "\n",
    "savefig(\"../imshow.png\")\n",
    "\n",
    "\n",
    "indices = partialsortperm(c[:], 1:1000, rev=true)\n",
    "\n",
    "close(\"all\"); plt.scatter(c_0[indices], c[indices]);plt.plot(\n",
    "    [minimum(c_0[indices]), maximum(c_0[indices])],[minimum(c_0[indices]), maximum(c_0[indices])]\n",
    "    ); savefig(\"../trial.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cc69f-a81b-469f-8fc3-93ba28ad4bad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparing algos for different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080e234-47be-4db0-9a2c-9179fe08e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise, PhyloTools, TreeTools, DCAUtils, JLD2, PyPlot, Statistics, DelimitedFiles\n",
    "using AncestralSequenceReconstruction # core package\n",
    "using JLD2 # used to load ArDCA models\n",
    "using TreeTools # to handle p\n",
    "using ArDCA, KitMSA\n",
    "\n",
    "nat_msa  = read_fasta_alignment(\"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\", 0.9);\n",
    "w = compute_weights(nat_msa, 22, 0.2)[1];\n",
    "@load \"../data_Genie/pars_dbd.jld2\"; h = h_dbd; J = J_dbd;\n",
    "@load \"../data_Anc/3_start_seq_and_sweeps4DBD_ASR.jld2\"\n",
    "\n",
    "q = 21; L =76;\n",
    "\n",
    "#=@load \"../data_Genie/3_seqs_sim.jld2\";\n",
    "@load \"../data_Genie/cie_dbd.jld2\";\n",
    "sweeps_sim = res_all[1].steps ./ L; =#\n",
    "\n",
    "\n",
    "#@time m1 = PhyloTools.info_timescales(res_all[1].step_msa, nat_msa, h, J, res_all[1].steps);\n",
    "\n",
    "\n",
    "tree_file = \"../data_Anc/DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301.nwk\"\n",
    "tree = read_tree(tree_file, node_data_type = Seq);\n",
    "dd = [distance(tree.root, a) for a in leaves(tree)];\n",
    "\n",
    "branch_d = mean([distance(tree.root, a) for a in leaves(tree)]);\n",
    "#mus = sweeps[[1,2,3,4,6]] ./ branch_d;\n",
    "mus = readdlm(\"../data_Anc/OFF_3_seq_DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301/mus.txt\")[:]\n",
    "sweeps = mus .* branch_d;\n",
    "\n",
    "\n",
    "folder = \"../data_Anc/OFF_3_seq_DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301\"\n",
    "    \n",
    "sweeps_on_tree = []; distances_on_tree = []; for mu in mus \n",
    "    ts, ds = PhyloTools.extract_distances(tree_file, joinpath(folder,\n",
    "            \"seq1/seq1_mu$(round(mu,digits = 2)).fa\"), Int.(start_msa[:,1]))\n",
    "    push!(sweeps_on_tree, ts.*mu)   \n",
    "    push!(distances_on_tree, ds./L)   \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "for i in 1:length(mus)\n",
    "close(\"all\");plt.plot(sweeps_sim, mean(m1.cie_t[:,varr], dims = 2), color = \"blue\"); plt.plot(\n",
    "    sweeps_sim, mean(m1.cie_t[:,cons], dims = 2), color = \"green\"); plt.plot(sweeps_sim, \n",
    "    mean(m1.cie_t[:,epis], dims = 2), color = \"red\"); plt.scatter(sweeps_on_tree[i], \n",
    "        distances_on_tree[i], color = \"grey\") \n",
    "plt.xlabel(\"Sweeps\");plt.xscale(\"log\"); plt.title(\"MU = $(mus[i])\"); savefig(\"../trial$(i).png\") \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "mus1 = [1., 10., 50., 100., 200.];\n",
    "\n",
    "alpha = 100.;\n",
    "idx = 2;\n",
    "\n",
    "step_msa_1 = [];step_msa_2 = [];step_msa_3 = []; res_all1 = []; res_all2 = []; res_all3 = [];\n",
    "for n in 1:length(mus1) \n",
    "    @time res1 = run_evolution_ontree(Int.(start_msa[:,idx]), tree_file, \n",
    "    h, alpha .* J, mu = mus1[n], p = 0.5); \n",
    "    push!(res_all1, res1)\n",
    "    push!(step_msa_1, msa_from_leafs(res1))\n",
    "end\n",
    "\n",
    "\n",
    "for n in 1:length(mus1)\n",
    "    leavestofasta(\"../res_algos/alpha$(alpha)_potts_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\", res_all1[n]) \n",
    "end\n",
    "\n",
    "res_ASR = zeros(Int, 3, L, length(mus1));\n",
    "pp = Matrix{Matrix{Float64}}(undef, 3, length(mus1));\n",
    "rec_msas = Matrix{Matrix{Int}}(undef, 3, length(mus1));\n",
    "#rec_msas_reshuf = Matrix{Matrix{Int}}(undef, 3, length(mus));\n",
    "ens = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "hams = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "#ens_reshuf = Matrix{Array{Float64,1}}(undef, 3, length(mus));\n",
    "#hams_reshuf = Matrix{Array{Float64,1}}(undef, 3, length(mus));\n",
    "ens_ML =  zeros(3, length(mus1));\n",
    "hams_ML =  zeros(3, length(mus1));\n",
    "\n",
    "    \n",
    "    for n in 1:length(mus1)\n",
    "        file_seqs = \"../res_algos/alpha$(alpha)_potts_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        mu = infer_mu(tree_file, file_seqs)\n",
    "        res, p = Felsenstein2(file_seqs, tree_file, file_seqs, mu)\n",
    "        res_ASR[idx,:,n] .= Int.(res)\n",
    "        pp[idx,n] = p\n",
    "        rec_msas[idx,n] = sampling_ANC(pp[idx,n], n_seq = 500)\n",
    "        hams[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), rec_msas[idx,n])\n",
    "        ens[idx,n] = PhyloTools.energy(rec_msas[idx,n], h, J)\n",
    "        #@time rec_msas_reshuf[idx,n] = reshuffle_entr(rec_msas[idx,n], h, J, temp = 0.2)\n",
    "        #hams_reshuf[idx,n] = ham_dist(Int.(start_msa[:,idx]), rec_msas_reshuf[idx,n])\n",
    "        #ens_reshuf[idx,n] = energy(rec_msas_reshuf[idx,n], h, J)\n",
    "        hams_ML[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), res_ASR[idx,:,n])\n",
    "        ens_ML[idx,n] = PhyloTools.energy(res_ASR[idx,:,n], h, J)\n",
    "    end\n",
    "\n",
    "\n",
    "nat_file = \"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\";\n",
    "arnet,arvar=ardca(nat_file);ar_model = AutoRegressiveModel(arnet);\n",
    "\n",
    "res_ASR_arDCA = zeros(Int, 3, L, length(mus1));\n",
    "\n",
    "\n",
    "    @time for n in 1:length(mus1)\n",
    "        fasta_file = \"../res_algos/alpha$(alpha)_potts_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    \n",
    "        strategy = ASRMethod(;joint = false, # (default) - joint reconstruction not functional yet\n",
    "            ML = true, # (default)\n",
    "            verbosity = 1, # the default is 0. \n",
    "            optimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "            optimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "            repetitions = 1, # (default) - for Bayesian reconstruction, multiple repetitions of the reconstruction process can be done to sample likely ancestors\n",
    "            );\n",
    "        opt_tree, reconstructed_sequences = infer_ancestral(\n",
    "            tree_file, fasta_file, ar_model, strategy\n",
    "            );\n",
    "        res_ASR_arDCA[idx,:,n] = KitMSA.string2vec(reconstructed_sequences[\"NODE_1\"]);\n",
    "        node_list=[\"NODE_1\"];\n",
    "        \n",
    "        \n",
    "        #this commented part is for the bayesian arDCA method\n",
    "        strategy_bayesian = ASRMethod(;\n",
    "\tjoint = false, # (default) - joint reconstruction not functional yet\n",
    "\tML = false, # (default)\n",
    "\tverbosity = 1, # the default is 0. \n",
    "\toptimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "\toptimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "\trepetitions = 100,\n",
    "\n",
    ")\n",
    "        \n",
    "    file_out = \"../res_algos/ardca_inf/alpha$(alpha)_ardca_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\";\n",
    "        infer_ancestral(\n",
    "               tree_file, fasta_file, ar_model, strategy_bayesian;\n",
    "               alignment_per_node=true, node_list = [\"NODE_1\"], outfasta = file_out);\n",
    "    println(n)\n",
    "    end \n",
    "\n",
    "rec_msas_arDCA = Matrix{Matrix{Int}}(undef, 3, length(mus1));\n",
    "ens_arDCA = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "hams_arDCA = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "ens_ML_arDCA =  zeros(3, length(mus1));\n",
    "hams_ML_arDCA =  zeros(3, length(mus1));\n",
    "\n",
    "\n",
    "\n",
    "    for n in 1:length(mus1)\n",
    "        \n",
    "        hams_ML_arDCA[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), res_ASR_arDCA[idx,:,n])\n",
    "        ens_ML_arDCA[idx,n] = PhyloTools.energy(res_ASR_arDCA[idx,:,n], h, J)\n",
    "    \n",
    "        rec_msas_arDCA[idx,n] = read_fasta_alignment(\"../res_algos/ardca_inf/alpha$(alpha)_ardca_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2))_NODE_1.fa\", 0.9);\n",
    "        \n",
    "        hams_arDCA[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), Int.(rec_msas_arDCA[idx,n]))\n",
    "        ens_arDCA[idx,n] = PhyloTools.energy(rec_msas_arDCA[idx,n], h, J)\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "close(\"all\"); \n",
    "    plt.errorbar(mus1, [mean(hams[idx,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams[idx,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    plt.scatter(mus1, hams_ML[1,:]./L, marker = \"X\", color = \"blue\", label = \"Felse ML\");\n",
    "    \n",
    "plt.errorbar(mus1, [mean(hams_arDCA[idx,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[idx,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    plt.scatter(mus1, hams_ML_arDCA[1,:]./L, marker = \"X\", color = \"red\", label = \"arDCA ML\");\n",
    "\n",
    "plt.xlabel(\"Mutation rate\");\n",
    "plt.ylabel(\"Hamming distance\");\n",
    "plt.title(\"Alpha = $(alpha)\");\n",
    "    plt.legend(); savefig(\"../prova_seq$(idx)_alpha$(alpha).png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2684a-2752-4ccb-bbf2-40574cd04ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "idx = 1;mus1 = [1., 10., 50., 100., 200.];\n",
    "\n",
    "alphas = [0.01, 0.1, 1., 10., 100.];\n",
    "c = [\"blue\", \"red\", \"green\", \"orange\", \"purple\"];\n",
    "\n",
    "\n",
    "num = 1;\n",
    "close(\"all\"); \n",
    "for alpha in alphas\n",
    "\n",
    "\n",
    "res_ASR = zeros(Int, 3, L, length(mus1));\n",
    "pp = Matrix{Matrix{Float64}}(undef, 3, length(mus1));\n",
    "rec_msas = Matrix{Matrix{Int}}(undef, 3, length(mus1));\n",
    "#rec_msas_reshuf = Matrix{Matrix{Int}}(undef, 3, length(mus));\n",
    "ens = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "hams = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "#ens_reshuf = Matrix{Array{Float64,1}}(undef, 3, length(mus));\n",
    "#hams_reshuf = Matrix{Array{Float64,1}}(undef, 3, length(mus));\n",
    "ens_ML =  zeros(3, length(mus1));\n",
    "hams_ML =  zeros(3, length(mus1));\n",
    "\n",
    "    \n",
    "    for n in 1:length(mus1)\n",
    "        file_seqs = \"../res_algos/alpha$(alpha)_potts_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        mu = infer_mu(tree_file, file_seqs)\n",
    "        res, p = Felsenstein2(file_seqs, tree_file, file_seqs, mu)\n",
    "        res_ASR[idx,:,n] .= Int.(res)\n",
    "        pp[idx,n] = p\n",
    "        rec_msas[idx,n] = sampling_ANC(pp[idx,n], n_seq = 500)\n",
    "        hams[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), rec_msas[idx,n])\n",
    "        ens[idx,n] = PhyloTools.energy(rec_msas[idx,n], h, J)\n",
    "        #@time rec_msas_reshuf[idx,n] = reshuffle_entr(rec_msas[idx,n], h, J, temp = 0.2)\n",
    "        #hams_reshuf[idx,n] = ham_dist(Int.(start_msa[:,idx]), rec_msas_reshuf[idx,n])\n",
    "        #ens_reshuf[idx,n] = energy(rec_msas_reshuf[idx,n], h, J)\n",
    "        hams_ML[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), res_ASR[idx,:,n])\n",
    "        ens_ML[idx,n] = PhyloTools.energy(res_ASR[idx,:,n], h, J)\n",
    "    end\n",
    "\n",
    "\n",
    "nat_file = \"../Gen.jl/data/alignments/natural/DBD_alignment.uniref90.cov80.a2m\";\n",
    "\n",
    "\n",
    "rec_msas_arDCA = Matrix{Matrix{Int}}(undef, 3, length(mus1));\n",
    "ens_arDCA = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "hams_arDCA = Matrix{Array{Float64,1}}(undef, 3, length(mus1));\n",
    "\n",
    "    for n in 1:length(mus1)    \n",
    "        rec_msas_arDCA[idx,n] = read_fasta_alignment(\"../res_algos/ardca_inf/alpha$(alpha)_ardca_seq$(idx)_mu$(round(mus1[n], \n",
    "        digits = 2))_NODE_1.fa\", 0.9);\n",
    "        \n",
    "        hams_arDCA[idx,n] = ham_dist_nogap(Int.(start_msa[:,idx]), Int.(rec_msas_arDCA[idx,n]))\n",
    "        ens_arDCA[idx,n] = PhyloTools.energy(rec_msas_arDCA[idx,n], h, J)\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #=plt.errorbar(mus1, [mean(hams[idx,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams[idx,n])./L for n in 1:length(mus1)], \n",
    "    color = c[num], linewidth = 3.0, label = \"Felse alpha = $(alpha)\"); =#\n",
    "    #plt.scatter(mus1, hams_ML[idx,:]./L, marker = \"X\", color = \"blue\", label = \"Felse ML\");\n",
    "    \n",
    "plt.errorbar(mus1, [mean(hams_arDCA[idx,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[idx,n])./L for n in 1:length(mus1)], \n",
    "    color = c[num], alpha = 0.3, label = \"arDCA alpha = $(alpha)\"); \n",
    "    #plt.scatter(mus1, hams_ML_arDCA[idx,:]./L, marker = \"X\", color = \"red\", label = \"arDCA ML\");\n",
    "\n",
    "\n",
    "\n",
    "num+=1\n",
    "           \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Mutation rate\");\n",
    "plt.ylabel(\"Hamming distance\");\n",
    "\n",
    "    plt.legend(); savefig(\"../prova_seq$(idx)_different_alphas_arDCA.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
